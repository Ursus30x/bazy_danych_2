\documentclass[12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[polish]{babel}
\usepackage[T1]{fontenc}
\usepackage{geometry}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{longtable}
\usepackage{hyperref}
\usepackage{float}

\geometry{a4paper, margin=1in}

\title{Sprawozdanie z projektu: \textit{Struktury Baz Danych} \\
\large Zadanie 2: Organizacja Indeksowo-Sekwencyjna (ISAM)}
\author{Jakub Szymczyk\\
        Nr albumu: 198134}
\date{\today}

\begin{document}

\maketitle

\section{Wstęp}

Celem drugiego zadania projektowego było zaprojektowanie i zaimplementowanie indeksowo-sekwencyjnej organizacji pliku (ISAM -- \textit{Indexed Sequential Access Method}). Projekt wymagał symulacji dostępu blokowego do pamięci dyskowej oraz zbadania wpływu parametrów konfiguracyjnych na wydajność struktury.

Kluczowym aspektem ISAM jest utrzymywanie rekordów w porządku sekwencyjnym w obszarze głównym, przy jednoczesnym obsłużeniu wstawiania nowych danych za pomocą obszaru nadmiarowego (Overflow) oraz okresowej reorganizacji.

Projekt składa się z trzech głównych modułów:
\begin{itemize}
    \item \textbf{DiskManager (C++)} -- warstwa abstrakcji symulująca dysk, obsługująca odczyt i zapis stron oraz zliczająca operacje wejścia/wyjścia (I/O).
    \item \textbf{ISAM (C++)} -- logika struktury danych, obsługa indeksu rzadkiego, łańcuchów przepełnień oraz procesu reorganizacji.
    \item \textbf{Eksperymenty (Bash/Python)} -- automatyzacja testów i wizualizacja wyników.
\end{itemize}

\section{Implementacja}

Struktura danych została zrealizowana w oparciu o trzy logiczne i fizyczne pliki:
\begin{enumerate}
    \item \textbf{Plik Indeksu (Index File)} -- przechowuje pary \texttt{(Klucz, NumerStrony)}. Zastosowano indeks rzadki (sparse index), wskazujący na najmniejszy klucz na danej stronie w pliku głównym.
    \item \textbf{Plik Główny (Primary Area)} -- przechowuje rekordy posortowane według klucza głównego. Dane są zorganizowane w strony o stałym rozmiarze (współczynnik blokowania $b=4$).
    \item \textbf{Plik Nadmiarowy (Overflow Area)} -- przechowuje rekordy, które nie zmieściły się na stronach głównych. Rekordy tworzą listy jednokierunkowe podpięte pod odpowiednie strony główne.
\end{enumerate}

\subsection{Struktura Rekordu i Strony}

Rekord składa się z klucza (\texttt{uint32}), danych (\texttt{uint32}), wskaźnika do overflow oraz flagi usunięcia.
Strona (\texttt{Page}) jest jednostką transferu danych między dyskiem a pamięcią. Zawiera tablicę rekordów, licznik zajętości oraz wskaźnik na początek łańcucha overflow.

\subsection{Operacje}

\subsubsection{Wyszukiwanie (Read)}
Algorytm najpierw przeszukuje indeks (wczytywany stronami), aby znaleźć odpowiednią stronę w pliku głównym. Następnie strona ta jest wczytywana do bufora. Jeśli szukany klucz nie znajduje się na stronie głównej, algorytm podąża za wskaźnikiem \texttt{overflowPointer} i przeszukuje łańcuch w pliku Overflow.

\subsubsection{Wstawianie (Insert)}
Jeśli na docelowej stronie w pliku głównym jest miejsce, rekord jest wstawiany z zachowaniem posortowania. W przeciwnym razie rekord trafia do pliku Overflow (zawsze na koniec pliku, \textit{append}) i jest logicznie wpinany w łańcuch wskaźników tak, aby zachować rosnącą kolejność kluczy w ramach łańcucha.

\subsubsection{Reorganizacja}
Proces reorganizacji jest kluczowy dla utrzymania wydajności ISAM. Przebiega on następująco:
\begin{enumerate}
    \item Utworzenie nowych, tymczasowych plików.
    \item Sekwencyjny odczyt starej struktury (strona po stronie + jej overflow).
    \item \textbf{Sortowanie} pobranych rekordów w pamięci operacyjnej (aby scalić dane z Overflow i Primary).
    \item Zapis do nowego pliku głównego z uwzględnieniem współczynnika wypełnienia $\alpha$ (Alpha).
    \item Odbudowa indeksu.
    \item Podmiana plików starych na nowe.
\end{enumerate}

Reorganizacja może być wywołana ręcznie lub automatycznie, gdy stosunek rekordów w Overflow do rekordów w Primary przekroczy zadany próg (\texttt{Threshold}).

\section{Opis eksperymentu}

Celem eksperymentu było zbadanie wpływu dwóch kluczowych parametrów na wydajność bazy danych:
\begin{itemize}
    \item \textbf{Współczynnik $\alpha$ (Alpha)} -- określa stopień wypełnienia strony głównej tuż po reorganizacji. Badano wartości 0.5 (duży zapas miejsca) oraz 0.9 (ciasne upakowanie).
    \item \textbf{Próg reorganizacji (Threshold)} -- określa tolerancję na wielkość obszaru Overflow (stosunek $V/N$). Badano zakres od 0.05 do 1.0.
\end{itemize}

\subsection{Metodologia}
W każdym przebiegu testowym:
\begin{enumerate}
    \item Wyczyszczono bazę danych.
    \item Wstawiono losowo 5000 rekordów (generując potencjalne kolizje i overflow).
    \item Wykonano 1000 losowych operacji wyszukiwania (Search).
\end{enumerate}
Mierzono liczbę wykonanych reorganizacji oraz całkowitą liczbę operacji odczytu i zapisu stron dyskowych.

\section{Wyniki eksperymentu}

\subsection{Częstotliwość reorganizacji}

Wykres na Rysunku~\ref{fig:reorgs} przedstawia zależność liczby reorganizacji od przyjętego progu (Threshold) dla dwóch wartości parametru Alpha.

\begin{figure}[H]
\centering
\includegraphics[width=0.85\linewidth]{../charts/reorgs_vs_threshold.png}
\caption{Wpływ progu reorganizacji na liczbę wykonanych reorganizacji dla różnych wartości $\alpha$.}
\label{fig:reorgs}
\end{figure}

\textbf{Wnioski:}
\begin{itemize}
    \item Dla $\alpha=0.9$ (linia pomarańczowa) liczba reorganizacji jest drastycznie wyższa niż dla $\alpha=0.5$. Wynika to z faktu, że pozostawienie tylko 10\% wolnego miejsca na stronie powoduje bardzo szybkie jej przepełnienie przy wstawianiu nowych danych.
    \item Niski Threshold (np. 0.05) wymusza niemal ciągłe reorganizacje, co jest bardzo kosztowne.
\end{itemize}

\subsection{Koszt zapisu (Writes)}

Rysunek~\ref{fig:writes} obrazuje całkowitą liczbę operacji zapisu na dysk. Jest to bezpośrednio skorelowane z liczbą reorganizacji, ponieważ każda reorganizacja wymaga przepisania całej bazy danych.

\begin{figure}[H]
\centering
\includegraphics[width=0.85\linewidth]{../charts/writes_vs_threshold.png}
\caption{Całkowita liczba operacji zapisu w funkcji progu reorganizacji.}
\label{fig:writes}
\end{figure}

Widać wyraźnie, że dla $\alpha=0.9$ i niskiego progu reorganizacji koszt zapisu jest ogromny (ponad 15~000 operacji). Zwiększenie progu reorganizacji pozwala znacząco zredukować obciążenie dysku zapisami.

\subsection{Analiza Trade-off (Odczyty)}

Najciekawszych wniosków dostarcza analiza odczytów przedstawiona na Rysunku~\ref{fig:reads_tradeoff}. Wykres ten rozbija całkowity koszt odczytów na:
\begin{itemize}
    \item \textbf{Maintenance (czerwona linia)} -- odczyty zużyte na proces reorganizacji.
    \item \textbf{Operational (zielona linia)} -- odczyty zużyte na właściwe wyszukiwanie i wstawianie rekordów.
\end{itemize}

\begin{figure}[H]
\centering
\includegraphics[width=0.85\linewidth]{../charts/reads_tradeoff_alpha_0_9.png}
\caption{Analiza składowych kosztu odczytu dla $\alpha=0.9$. Widoczny kompromis między kosztem utrzymania a kosztem operacyjnym.}
\label{fig:reads_tradeoff}
\end{figure}

\textbf{Analiza:}
\begin{itemize}
    \item Wraz ze wzrostem Threshold spada koszt utrzymania (rzadsze reorganizacje).
    \item Jednakże, na prawym krańcu wykresu (Threshold > 0.8) widzimy, że linia zielona (koszt operacyjny) zaczyna rosnąć. Dzieje się tak, ponieważ rzadkie sprzątanie powoduje wydłużanie się łańcuchów w obszarze Overflow.
    \item Każde wyszukiwanie rekordu w długim łańcuchu Overflow wymaga wielu odczytów dyskowych, co negatywnie wpływa na wydajność bieżącą bazy.
\end{itemize}

\section{Wnioski końcowe}

Przeprowadzone eksperymenty potwierdziły teoretyczne założenia metody ISAM.
\begin{enumerate}
    \item Istnieje silna zależność między współczynnikiem wypełnienia $\alpha$ a wydajnością. Wartość $\alpha=0.9$ oszczędza miejsce na dysku (czego nie mierzono wprost, ale wynika z teorii), ale generuje bardzo duży narzut operacji I/O związany z częstymi reorganizacjami. Wartość $\alpha=0.5$ jest bezpieczniejszym wyborem dla dynamicznie zmieniających się danych.
    \item "Zbyt gorliwe" sprzątanie (niski Threshold) jest nieopłacalne. Koszt ciągłego przepisywania pliku przewyższa zyski z idealnego uporządkowania danych.
    \item Istnieje optimum progu reorganizacji (w badanym przypadku ok. 0.6--0.8), gdzie suma kosztów utrzymania i kosztów operacyjnych jest najniższa. Przekroczenie tego progu powoduje degradację wydajności wyszukiwania z powodu zbyt długich łańcuchów w obszarze nadmiarowym.
\end{enumerate}

Implementacja poprawnie realizuje mechanizmy ISAM, w tym obsługę indeksu rzadkiego oraz łańcuchów przepełnień, co potwierdzają wyniki testów i zgodność charakterystyk z modelem teoretycznym.

\end{document}