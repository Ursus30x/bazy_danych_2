\documentclass[12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[polish]{babel}
\usepackage[T1]{fontenc}
\usepackage{geometry}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{longtable}
\usepackage{hyperref}

\geometry{a4paper, margin=1in}

\title{Sprawozdanie z projektu: \textit{Struktury Baz Danych} \\
\large Sortowanie z użyciem wielkich buforów}
\author{Jakub Szymczyk\\
        Nr albumu: 198134}
\date{\today}

\begin{document}

\maketitle

\section{Wstęp}

Celem projektu było zaprojektowanie i implementacja algorytmu sortowania plików sekwencyjnych. 
Do osiągnięcia założeń projektu wybrano algorytm sortowania z użyciem wielkich buforów, 
który pozwala na efektywne przetwarzanie dużych ilości danych w pamięci, minimalizując liczbę 
operacji dyskowych. Projekt składa się także z warstwy abstrakcji reprezentującej 
operacje odczytu i zapisu do pliku oraz interfejsu CLI umożliwiającego przetestowanie algorytmu 
dla różnych danych podanych przez użytkownika.

Projekt składa się z trzech głównych modułów:
\begin{itemize}
    \item \textbf{C++} -- implementacja głównej logiki programu oraz symulacji buforów i taśm,
    \item \textbf{Python} -- generowanie wykresów na podstawie wyników eksperymentów,
    \item \textbf{Bash} -- skrypty do automatycznego przeprowadzenia testów oraz budowania całego projektu i sprawozdania.
\end{itemize}

\section{Implementacja}

Zadanie polegało na implementacji algorytmu sortowania pliku metodą scalania z użyciem wielkich buforów, zrealizowanego 
w formie symulacji operacji dyskowych. Program symuluje odczyt i zapis bloków danych z dysku oraz wykorzystuje
wiele dostępnych buforów pamięci, co pozwala na efektywną pracę.

\subsection{Wybór algorytmu}

Zastosowano metodę \textit{scalania z użyciem wielkich buforów} (ang.~\textit{merge sort with large buffers}), która jest efektywna przy dużych ilościach danych
i umożliwia redukcję liczby operacji dyskowych poprzez grupowanie danych w duże bufory. 

\subsection{Typ rekordu}

W projekcie wykorzystywany jest prosty typ rekordu oparty na typie \texttt{uint32\_t}, reprezentujący wartości 
czasowe jako uniksowy znacznik czasu (ang.~\textit{UNIX timestamp}). Pomimo tego, że w standardzie UNIX timestamp każda wartość z przedziału \texttt{uint32\_t} 
jest wartością prawidłową, na potrzeby i wymagania projektu wartość 0 została uznana za padding/NULL. 

Wszystkie dane są zapisywane w formacie binarnym i przechowywane w plikach dyskowych, symulując działanie taśmy.

\subsection{Struktura projektu}

Projekt został podzielony na trzy główne moduły:

\begin{itemize}
    \item \textbf{main.cpp} -- punkt wejścia programu, obsługa argumentów linii poleceń oraz inicjalizacja struktur,
    \item \textbf{tape.hpp} -- symulacja taśmy dyskowej i operacji odczytu/zapisu bloków,
    \item \textbf{tapeSort.hpp} -- implementacja algorytmu sortowania z wielkimi buforami.
\end{itemize}

\subsection{Format pliku testowego}

Pliki testowe zawierają wartości całkowite oddzielone przecinkami (np.~\texttt{1,2,3,4,5}).
Program wczytuje dane z pliku tekstowego i konwertuje je do formatu binarnego.

\subsection{Symulacja taśmy}

Klasa \texttt{Tape} symuluje działanie taśmy dyskowej, przechowując dane w plikach binarnych. 
Wszystkie operacje odczytu i zapisu są wykonywane blokowo. Buforowanie odbywa się na poziomie bloków,
a program śledzi liczbę operacji wejścia/wyjścia.

\subsection{Algorytm sortowania}

W algorytmie wykorzystano dwa etapy:

\begin{enumerate}
    \item \textbf{Tworzenie runów} -- dane są wczytywane do pamięci (bufora) i sortowane. Następnie posortowane 
    sekwencje są zapisywane z powrotem na taśmie jako \textit{runy} (ang.~\textit{runs}).
    \item \textbf{Scalanie runów} -- wykonywane jest scalanie wielu runów w jeden, z wykorzystaniem kolejki 
    priorytetowej (min-heap) dla efektywnego scalania.
\end{enumerate}

W procesie scalania używane są buforowe struktury danych oraz algorytm \textit{multi-way merge}, który pozwala 
na scalanie wielu sekwencji w czasie logarytmicznym względem liczby runów.

\subsection{Tworzenie runów}

Algorytm tworzenia runów polega na wczytaniu danych do pamięci buforowej, posortowaniu ich oraz zapisaniu wyniku na taśmie \textit{in-place}. W~każdej iteracji wczytywanych jest dokładnie $n$ bloków danych (gdzie $n$ to liczba bloków w buforze) do pamięci operacyjnej, następnie są one sortowane przy użyciu algorytmu \texttt{std::sort} z~biblioteki standardowej C++ i zapisywane z~powrotem w to samo miejsce na taśmie jako posortowany run. Proces ten powtarzany jest do momentu przetworzenia całego pliku.

Kluczową cechą tej fazy jest operowanie na jednej taśmie -- runy są tworzone bezpośrednio w miejscu oryginalnych danych, co eliminuje potrzebę dodatkowej przestrzeni dyskowej na tym etapie. Rozmiar pojedynczego runu wynosi dokładnie $n$ bloków (z wyjątkiem ostatniego runu, który może być mniejszy).

\subsection{Scalanie runów}

Proces scalania przebiega w cyklach, wykorzystując strategię $(n-1)$-drogowego scalania, gdzie $n$ to liczba dostępnych buforów. W każdym cyklu:

\begin{enumerate}
    \item Program dzieli istniejące runy na grupy po $(n-1)$ runów.
    \item Dla każdej grupy przeprowadzane jest równoczesne scalanie wszystkich runów w grupie do jednego większego runu.
    \item Scalanie realizowane jest przy użyciu kolejki priorytetowej (min-heap), która utrzymuje najmniejszy element z każdego aktywnego runu.
    \item Scalony run jest zapisywany na pomocniczej taśmie tymczasowej.
\end{enumerate}

Po zakończeniu cyklu scalania:
\begin{itemize}
    \item Oryginalna taśma jest usuwana.
    \item Taśma tymczasowa zostaje przemianowana na nazwę taśmy oryginalnej.
    \item Proces powtarza się, aż pozostanie tylko jeden posortowany run.
\end{itemize}

Każdy cykl scalania zwiększa rozmiar runów $(n-1)$-krotnie, co prowadzi do logarytmicznej liczby cykli względem początkowej liczby runów.

\subsection{Liczba użytych taśm}

Istotną cechą implementacji jest minimalizacja liczby używanych taśm. Program operuje na \textbf{maksymalnie 2 taśmach jednocześnie}:

\begin{itemize}
    \item \textbf{Faza tworzenia runów}: wykorzystywana jest tylko jedna taśma -- dane są sortowane i zapisywane \textit{in-place}, bez potrzeby dodatkowej przestrzeni dyskowej.
    \item \textbf{Faza scalania runów}: program używa dwóch taśm -- oryginalnej (źródłowej) i tymczasowej (docelowej). Po zakończeniu każdego cyklu scalania następuje zamiana ról taśm poprzez usunięcie oryginalnej i przemianowanie tymczasowej.
\end{itemize}

Takie podejście znacząco redukuje wymagania dotyczące przestrzeni dyskowej w porównaniu do klasycznych implementacji sortowania zewnętrznego, które często wymagają trzech lub więcej taśm.

\subsection{Klasa \texttt{RecordType}}

Klasa \texttt{RecordType} reprezentuje pojedynczy rekord pliku. Posiada metodę do porównywania rekordów oraz 
konwersję na format tekstowy. Działa na zasadzie typu prostego \texttt{uint32\_t}, co pozwala na łatwe przechowywanie
i sortowanie.

\section{Opis eksperymentu}

Eksperyment został przeprowadzony w celu analizy skuteczności algorytmu sortowania z wielkimi buforami 
w zależności od liczby rekordów oraz wielkości bufora. 

\subsection{Parametry eksperymentu}

\begin{itemize}
    \item Liczba rekordów: 100, 200, 400, 800, 1600, 3200, 6400, 12\,800
    \item Wielkość bufora: 4, 16 bloki
    \item Rozmiar bloku: 10 rekordów (40 bajtów)
\end{itemize}

Dla każdego zestawu parametrów uruchamiano program i zapisywano:
\begin{itemize}
    \item liczbę faz sortowania,
    \item liczbę odczytów strony,
    \item liczbę zapisów strony.
\end{itemize}

\subsection{Metodologia}

Program został uruchomiony w środowisku bash, które automatycznie wywołuje eksperymenty dla różnych kombinacji parametrów. Wyniki są zapisywane do pliku tekstowego i przetwarzane przez skrypt w~języku Python do generowania wykresów.

\subsection{Wyniki teoretyczne}

Załóżmy, że:
\begin{itemize}
    \item $N$ -- liczba rekordów,
    \item $b$ -- liczba rekordów na blok (\textit{blocking factor}),
    \item $n$ -- liczba bloków w buforze.
\end{itemize}

Liczba początkowych runów: 
\begin{equation}
r = \left\lceil \frac{N}{n \cdot b} \right\rceil
\end{equation}

Liczba faz sortowania (cykli scalania):
\begin{equation}
\text{Fazy} = \lceil \log_n(r) \rceil
\end{equation}

Liczba operacji wejścia/wyjścia:
\begin{equation}
\text{Operacje} = 2 \cdot \frac{N}{b} \cdot (1 + \text{Fazy})
\end{equation}

\section{Wyniki eksperymentu}

\subsection{Zebrane dane}

W tabeli~\ref{tab:results_combined} przedstawiono zebrane wyniki eksperymentu dla różnych konfiguracji liczby rekordów i wielkości buforów. Dla każdej konfiguracji zmierzono liczbę faz scalania oraz łączną liczbę operacji odczytu i zapisu bloków.

\begin{table}[htbp]
\centering
\begin{tabular}{crrrrrr}
\toprule
\multirow{2}{*}{Liczba rekordów} & \multicolumn{3}{c}{Bufor 4 bloki} & \multicolumn{3}{c}{Bufor 16 bloków} \\
\cmidrule(lr){2-4} \cmidrule(lr){5-7}
& Fazy & Odczyty & Zapisy & Fazy & Odczyty & Zapisy \\
\midrule
100 & 1 & 20 & 20 & 0 & 10 & 10 \\
200 & 2 & 60 & 60 & 1 & 40 & 40 \\
400 & 3 & 160 & 160 & 1 & 80 & 80 \\
800 & 3 & 320 & 320 & 1 & 160 & 160 \\
1600 & 4 & 800 & 800 & 1 & 320 & 320 \\
3200 & 4 & 1600 & 1600 & 2 & 960 & 960 \\
6400 & 5 & 3840 & 3840 & 2 & 1920 & 1920 \\
12\,800 & 6 & 8960 & 8960 & 2 & 3840 & 3840 \\
\bottomrule
\end{tabular}
\caption{Zestawienie wyników eksperymentu dla buforów 4 i 16 bloków}
\label{tab:results_combined}
\end{table}

Warto zauważyć, że liczba operacji odczytu i zapisu jest zawsze identyczna, co wynika z charakteru algorytmu -- każdy odczytany blok musi zostać następnie zapisany po przetworzeniu.

\subsection{Analiza liczby faz scalania}

\subsubsection{Zależność od wielkości bufora}

Wykresy na rysunkach~\ref{fig:cycles_4} i~\ref{fig:cycles_16} przedstawiają zależność liczby faz scalania od liczby rekordów dla różnych wielkości buforów. Obserwacje te potwierdzają teoretyczną złożoność algorytmu:

\begin{itemize}
    \item Dla bufora 4~bloki liczba faz rośnie zgodnie z~zależnością $\lceil \log_3(r) \rceil$, gdzie $r$ to liczba początkowych runów, a~podstawa logarytmu wynika z~liczby scalanych runów jednocześnie $(n-1=3)$.
    \item Dla bufora 16~bloków podstawa logarytmu wynosi 15, co skutkuje znacznie wolniejszym wzrostem liczby faz.
    \item Dla 100~rekordów przy buforze 16~bloków obserwujemy 0~faz scalania, co oznacza, że wszystkie dane mieszczą się w~jednym runie po fazie tworzenia runów.
\end{itemize}

\begin{figure}[htbp]
\centering
\includegraphics[width=0.75\linewidth]{../charts/cycles_vs_records_buffer_4.png}
\caption{Liczba faz scalania w~funkcji liczby rekordów dla bufora 4~bloki. Widoczny jest logarytmiczny charakter wzrostu.}
\label{fig:cycles_4}
\end{figure}

\begin{figure}[htbp]
\centering
\includegraphics[width=0.75\linewidth]{../charts/cycles_vs_records_buffer_16.png}
\caption{Liczba faz scalania w~funkcji liczby rekordów dla bufora 16~bloków. Znacząco mniejsza liczba faz w~porównaniu do bufora 4~bloki.}
\label{fig:cycles_16}
\end{figure}

\subsubsection{Interpretacja wyników}

Analiza wyników prowadzi do następujących wniosków:

\begin{itemize}
    \item \textbf{Efekt rozmiaru bufora}: Czterokrotne zwiększenie rozmiaru bufora (z~4 do 16~bloków) redukuje liczbę faz scalania o~50--75\% dla większych zbiorów danych. Dla 12\,800~rekordów liczba faz spada z~6 do 2.
    
    \item \textbf{Próg wydajności}: Istnieje próg, poniżej którego zwiększanie bufora nie przynosi korzyści. Dla 100~rekordów i~bufora 16~bloków nie ma już faz scalania, więc dalsze zwiększanie bufora byłoby nieefektywne.
    
    \item \textbf{Zgodność z~teorią}: Wyniki eksperymentalne są zgodne z~przewidywaniami teoretycznymi. Liczba faz faktycznie rośnie logarytmicznie, co potwierdza poprawność implementacji.
\end{itemize}

\subsubsection{Analiza rozbieżności dla bufora 4~bloki}

Dla bufora 4~bloki obserwuje się systematyczne odchylenie liczby faz o~1 w~górę względem przewidywań teoretycznych. Na przykład:

\begin{itemize}
    \item Dla 400 rekordów: teoria przewiduje 2 fazy, praktyka daje 3 fazy
    \item Dla 800 rekordów: teoria przewiduje 2 fazy, praktyka daje 3 fazy
    \item Dla 1600 rekordów: teoria przewiduje 3 fazy, praktyka daje 4 fazy
\end{itemize}

Przyczyną tej rozbieżności jest sposób liczenia faz w~implementacji algorytmu. Analiza kodu źródłowego funkcji \texttt{merge()} ujawnia, że:

\begin{enumerate}
    \item \textbf{Faza 0 nie jest liczona}: Teoretyczny model zakłada, że tworzenie początkowych runów to "faza 0", podczas gdy implementacja rozpoczyna liczenie od 1 dopiero w~momencie pierwszego scalania.
    
    \item \textbf{Warunek zakończenia}: W~kodzie sprawdzany jest warunek \texttt{numRuns > 1}, co oznacza, że nawet jeśli po danym cyklu zostały tylko 2 runy, algorytm wykona jeszcze jedną fazę scalania. Teoretyczny wzór $\lceil \log_n(r) \rceil$ nie uwzględnia tej dodatkowej iteracji.
    
    \item \textbf{Efekt małej liczby scalanych runów}: Dla bufora 4~bloki używane jest scalanie 3-drożne ($(n-1) = 3$). Przy małej liczbie początkowych runów (np.~4--5 runów) model logarytmiczny daje wartość bliską dolnej granicy przedziału, podczas gdy rzeczywista implementacja musi wykonać pełną iterację pętli \texttt{while}.
\end{enumerate}

Matematycznie, dla bufora 4~bloki:
\begin{align*}
\text{Liczba początkowych runów: } r &= \left\lceil \frac{N}{4 \cdot 10} \right\rceil \\
\text{Teoretyczna liczba faz: } &= \lceil \log_3(r) \rceil \\
\text{Praktyczna liczba faz: } &= \lceil \log_3(r) \rceil + 1
\end{align*}

gdzie dodatkowa faza wynika z~implementacyjnych szczegółów warunku zakończenia pętli scalania.

Dla bufora 16~bloków ta rozbieżność jest mniej widoczna, ponieważ przy scalaniu 15-drożnym liczba runów maleje znacznie szybciej i~często osiąga wartość 1 już po teoretycznej liczbie faz.

\subsection{Analiza operacji dyskowych}

\subsubsection{Porównanie wydajności}

Tabela~\ref{tab:disk_ops_summary} przedstawia łączną liczbę operacji dyskowych (odczyty + zapisy) dla różnych konfiguracji. Jest to kluczowa metryka wydajności, gdyż operacje dyskowe stanowią główne wąskie gardło w~algorytmach sortowania zewnętrznego.

\begin{table}[htbp]
\centering
\begin{tabular}{crrr}
\toprule
Liczba rekordów & Bufor 4 bloki & Bufor 16 bloków & Redukcja\\
\midrule
100 & 40 & 20 & 50\% \\
200 & 120 & 80 & 33\% \\
400 & 320 & 160 & 50\% \\
800 & 640 & 320 & 50\% \\
1600 & 1600 & 640 & 60\% \\
3200 & 3200 & 1920 & 40\% \\
6400 & 7680 & 3840 & 50\% \\
12\,800 & 17\,920 & 7680 & 57\% \\
\bottomrule
\end{tabular}
\caption{Łączna liczba operacji dyskowych (odczyty + zapisy) oraz procentowa redukcja przy zwiększeniu bufora z~4 do 16~bloków}
\label{tab:disk_ops_summary}
\end{table}

\begin{figure}[htbp]
\centering
\includegraphics[width=0.75\linewidth]{../charts/disk_ops_vs_records_buffer_4.png}
\caption{Liczba operacji dyskowych dla bufora 4~bloki. Wykres pokazuje nieliniowy wzrost wraz ze~zwiększaniem liczby rekordów.}
\label{fig:disk_ops_4}
\end{figure}

\begin{figure}[htbp]
\centering
\includegraphics[width=0.75\linewidth]{../charts/disk_ops_vs_records_buffer_16.png}
\caption{Liczba operacji dyskowych dla bufora 16~bloków. Znacząco mniejsza liczba operacji w~porównaniu do bufora 4~bloki.}
\label{fig:disk_ops_16}
\end{figure}

\subsubsection{Wnioski z~analizy operacji dyskowych}

Z przeprowadzonej analizy wynikają następujące obserwacje:

\begin{itemize}
    \item \textbf{Znacząca redukcja operacji}: Zwiększenie rozmiaru bufora z~4 do 16~bloków redukuje liczbę operacji dyskowych średnio o~50\%. Dla największego testowanego zbioru (12\,800~rekordów) redukcja wynosi 57\%, co przekłada się na~10\,240 operacji mniej.
    
    \item \textbf{Skalowanie}: Liczba operacji dyskowych rośnie szybciej niż liniowo względem liczby rekordów, co jest zgodne ze~wzorem teoretycznym $\text{Operacje} = 2 \cdot \frac{N}{b} \cdot (1 + \text{Fazy})$. Składnik $(1 + \text{Fazy})$ wprowadza nadliniową zależność.
    
    \item \textbf{Zgodność z~modelem teoretycznym}: Dla małych zbiorów danych (100--400~rekordów) wyniki praktyczne są niemal identyczne z~przewidywaniami teoretycznymi. Dla większych zbiorów obserwuje się niewielkie odchylenia, prawdopodobnie wynikające z~efektów związanych z~niepełnym wykorzystaniem ostatnich bloków i~zaokrągleniami.
    
    \item \textbf{Ekonomika pamięci}: Wyniki pokazują wyraźny trade-off między rozmiarem bufora a~wydajnością. Czterokrotne zwiększenie pamięci bufora daje dwukrotną redukcję operacji dyskowych, co sugeruje malejące zyski krańcowe przy dalszym zwiększaniu bufora.
\end{itemize}

\subsubsection{Analiza rozbieżności między teorią a~praktyką}

Wraz ze wzrostem liczby rekordów obserwuje się rosnące odchylenia między teoretyczną a~praktyczną liczbą operacji dyskowych. Zjawisko to ma kilka przyczyn wynikających bezpośrednio z~implementacji algorytmu:

\paragraph{Efekt niepełnych bloków}

Model teoretyczny zakłada idealne wypełnienie wszystkich bloków, podczas gdy w~praktyce:

\begin{itemize}
    \item \textbf{Ostatni blok runu}: Po fazie tworzenia runów ostatni blok każdego runu może być niepełny. Dla $N$ rekordów i~bufora $n$ bloków po $b$ rekordów każdy, liczba początkowych runów wynosi $r = \lceil \frac{N}{n \cdot b} \rceil$. Ostatni run często zawiera mniej niż $n$ pełnych bloków.
    
    \item \textbf{Padding w~buforze wyjściowym}: W~implementacji funkcji \texttt{merge()} bufor wyjściowy jest zapisywany, gdy osiągnie rozmiar \texttt{recordsPerBlock}. Ostatnia partia danych w~każdym scalonym runie może nie wypełnić pełnego bloku, ale i~tak jest zapisywana jako osobny blok.
    
    \item \textbf{Kumulacja niepełnych bloków}: W~kolejnych fazach scalania te niepełne bloki propagują się przez algorytm. Każda faza może generować dodatkowe niepełne bloki na końcach scalonych runów.
\end{itemize}

\paragraph{Wnioski}

Rozbieżności między modelem teoretycznym a~praktyką są naturalną konsekwencją dyskretnej natury bloków i~zaokrągleń występujących w~rzeczywistych implementacjach.
\section{Wnioski końcowe}

Przeprowadzone eksperymenty potwierdziły skuteczność algorytmu sortowania z~wielkimi buforami. Liczba faz scalania rośnie logarytmicznie, zgodnie z~teorią, a~zwiększenie rozmiaru bufora z~4 do 16~bloków redukuje operacje dyskowe średnio o~50\%. Implementacja wykorzystująca maksymalnie 2~taśmy skutecznie minimalizuje wymagania pamięciowe.
\\
\\
Zaobserwowano systematyczne rozbieżności między teorią a~praktyką. Dla bufora 4~bloki implementacja wykonuje o~1 fazę więcej z~uwagi na warunki zakończenia pętli. Dodatkowo, niepełne bloki generują overhead, który rośnie wraz z~liczbą rekordów -- procentowe odchylenie jednak maleje (z~33\% do 17\% dla największych zbiorów).
\\
\\
Algorytm stanowi efektywne rozwiązanie dla sortowania dużych zbiorów danych i~ma praktyczne zastosowanie w~systemach bazodanowych . Kluczem do optymalnej wydajności jest odpowiedni dobór rozmiaru bufora względem wielkości danych -- czterokrotne zwiększenie bufora daje dwukrotną redukcję operacji, co wskazuje na malejące zyski krańcowe.

\end{document}